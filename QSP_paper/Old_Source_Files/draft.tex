\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{braket}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{float}
\usepackage{authblk}
\graphicspath{ {./figures} }

\begin{document}

\title{Approximate Quantum State Preparation is Iterated Sparse State Preparation on Linear Neighbor Architectures}
\author{Ralph Wang}
\author{Akshay Ajagekar}
\author{Fengqi You}
\affil{Cornell University, Ithaca, NY, USA, 14853}
\date{15 September 2023}
\maketitle

\section*{Abstract}
Quantum algorithms promise exponential speedups in many computational routines.
One important
subroutine in many such quantum algorithms is quantum state preparation. In this
work, we propose a novel, non-variational framework for quantum state 
preparation by iteratively applying sparse quantum state preparation methods.
The proposed framework is flexible with respect to CX gate count constraints,
preparation fidelity requirements, and hardware connectivity, without requiring
variational tuning.
We also give an explicit implementation for the linear nearest neighbor 
architecture, using CX
gates and single-qubit rotations, and compare it against exact state 
preparation using uniformly controlled gates (UCG) and against variational 
quantum circuit 
(VQC) approaches. The proposed method uses 25\% fewer CX gates compared to exact
state preparation and runs orders of magnitude faster than the VQC approaches.

\section{Introduction}
Quantum algorithms promise exponential speedups in many computation routines, 
such as quantum Fourier Transform \cite{shor1994algorithms} and solving linear 
systems \cite{PhysRevLett.103.150502}. Quantum state preparation, the encoding
of classical data onto the amplitudes of a quantum computer, is an
essential step in such quantum algorithms \cite{aaronson2015read}. Current
quantum computers experience significant noise and quantum state preparation
often contributes significantly towards the runtime cost of quantum
algorithms \cite{aaronson2015read}. Therefore, implementing quantum state preparation efficiently on
quantum computers is essential towards useful quantum algorithms on near term
quantum computers.

The cost of a quantum circuit is often measured in terms of gate count and
circuit depth \cite{1629135}. Gate count refers to the number of two-qubit gates in the
quantum circuit - single-qubit gates are not counted because they are much
simpler to implement and induce less noise \cite{1629135}. Most quantum 
algorithms use
control-X (CX) gates as their two-qubit gate \cite{PhysRevLett.103.150502, 1629135, zhang2020toward}; in this work, we follow suit, and
use the number of CX gates as the gate count. Circuit depth refers to the 
longest subsequence of non-commutative gates in the circuit. The greater 
the circuit depth, the longer it takes to execute, which leads to more noise 
from qubit decoherence \cite{10044235}.

The problem of efficient quantum state preparation has received much attention
over the years. Shende et al \cite{1629135} proposed an $O(n2^n)$ algorithm
for exact quantum state preparation using $O(2^n)$ CX gates, $O(2^n)$ circuit
depth, where $n$ is the number of qubits. Their algorithm starts by rotating 
the first qubit, then iteratively 
rotating successive qubits conditioned on preceding qubits, contributing both
a general framework of ``uniformly-controlled gates." Bergholm et al
\cite{bergholm2005quantum} proposed an optimization on the method from \cite{1629135}, reducing the number of
CX gates by a factor of two. Plesch and Bruckner \cite{PhysRevA.83.032302} 
adapted unitary 
synthesis optimizations from \cite{1629135} towards quantum state preparation,
reducing the gate count by a factor of 1/24. Sun et al proposed a 
depth-efficient decomposition of uniformly controlled rotations, leading to a 
quantum state preparation method with a constant factor more CX gates, but with
$O(\frac{2^n}{n})$ depth \cite{10044235}. They also showed how ancilla qubits could be used to
compress the circuit depth even further, sacrificing space for time. Zhang et al
took this idea one step further, proposing a method that prepares
$n$-qubit quantum states using $O(2^n)$ qubits, but only $O(n)$ depth \cite{zhang2022quantum}. All of
the proposed algorithms return asymptotically optimal gate counts in a
reasonable computation time. Unfortunately, asymptotically optimal is
exponential in the number qubits, and such large gate counts cannot be
feasibly implemented on near term quantum computers.

Another recent trend in the field has been to study sparse quantum state
preparation \cite{PhysRevA.106.022617}. Sparse quantum states on $n$ qubits are characterized by having
at most $m$ nonzero amplitudes, where $m < 2^n$. The efficient
preparation of sparse quantum states find applications in solving linear
systems \cite{PhysRevLett.103.150502}, the quantum Byzantine agreement \cite{10.1145/1060590.1060662}, among other quantum algorithms \cite{9272350}.
Many sparse quantum state preparation algorithms have been proposed.
Gleinig and Hoefler \cite{10.1109/DAC18074.2021.9586240} proposed an algorithm that starts with the
target sparse state, then iteratively merges the non-zero amplitudes together
until only one non-zero amplitude remains; reversing this process then generates
a gate sequence for preparing that non-zero state. By contrast, Malvetti et al
\cite{Malvetti2021quantumcircuits} proposed a general framework for implementing sparse isometries, which
includes quantum state preparation as a subset, although their algorithm takes
longer to compute. More recently, sparse state preparation using decision
diagrams was proposed to improve merging efficiency, achieving around 30\%
reduction in CX gate count when $m$ was $O(n^2)$ or larger \cite{PhysRevA.106.022617}. 

These existing algorithms generally assume that CX gates can be applied to any
two qubits. However, current state-of-the-art quantum computers, such as IBM's
433-qubit Osprey processor, allow CX gates to only be applied to
nearest-neighbor qubits \cite{bravyi2022future}. Each quantum computer has its own physical layout of
the qubits; to model these connectivity restrictions, much work has examined
adapting quantum algorithms towards linear nearest neighbor architectures, or
quantum hardware where the $i$th qubit's nearest neighbors are the $i-1$th and
$i+1$th qubit \cite{1629135, bergholm2005quantum, 4782917, Saeedi_Wille_Drechsler_2010}. 
In particular, \cite{bergholm2005quantum} showed how their UCG decomposition
scheme can be optimized for linear nearest neighbor architectures, however, even
with the optimization, the linear nearest neighbor restriction increases the
CX gate count by a factor of two.

One popular, hardware-adaptive alternative to exact quantum state preparation 
has been approximate encoding using variational quantum circuits \cite{PhysRevResearch.4.023136}. A generic, 
shallow, hardware-efficient quantum circuit is used to approximately prepare 
quantum states, then a variational optimization procedure is used to adjust the
single-qubit gates until the quantum 
circuit approximately prepares the desired state \cite{PhysRevA.98.032309}. This approach has the 
advantage of being hardware adaptive and often requiring fewer CX gates compared to the 
exact quantum state preparation methods \cite{Cerezo_Sone_Volkoff_Cincio_Coles_2021}. However, McClean et al \cite{McClean_Boixo_Smelyanskiy_Babbush_Neven_2018} proved that if the 
quantum circuit structure exhibits no biases towards any particular quantum 
state, then the gradient with respect to preparation fidelity vanishes 
exponentially, causing the angle-tuning procedure to take exponential time; the
authors dub this the ``barren plateau" problem. Local cost functions \cite{Cerezo_Sone_Volkoff_Cincio_Coles_2021}, cost
landscape tuning \cite{rivera2021avoiding}, and few-shot approximations \cite{PhysRevResearch.4.023136} have been examined as solutions
towards barren plateaus, but the problem remains open.

In this work, we address the problem of approximate, dense state preparation on
restricted connectivity hardwares without any variational optimization 
procedure. Specifically, we propose a novel 
framework for preparing dense quantum states by iteratively applying sparse 
quantum state preparation methods. In doing so, we suggest that advances in 
sparse quantum state preparation can be adapted to improving dense quantum state
preparation. To account for potential hardware connectivity restrictions, we
analyze our algorithm with respect to linear nearest neighbor connectivity then
discuss extensions towards other hardware connectivity graphs. We benchmark
our algorithm on randomly sampled dense quantum states, up to 14 qubits, and
compare it against the UCG method and two VQC-based methods. By comparing the
gate counts and computational runtimes, we demonstrate that our method is able
to find quickly find efficient gate sequences for high-fidelity quantum state 
preparation. The major contributions of this work are summarized as follows:
\begin{itemize}
  \item A novel, hardware-adaptive, non-variational framework for approximate 
    quantum state preparation is proposed.
  \item A connection between sparse quantum state preparation and approximate,
    dense quantum state preparation is established.
  \item A specific implementation of the proposed framework is described and
    shown to effectively prepare random quantum states.
\end{itemize}

In section 2, we define the approximate quantum state preparation
problem. In section 3, we describe some sparse state preparation methods 
then describe our proposed algorithm for dense quantum state
preparation using those sparse state preparation methods. In section 4, we
compare the proposed algorithm against exact quantum state preparation and two
variational quantum algorithms, comparing their CX gate counts and classical
computation times. We discuss the results and conclude in section 5.
Some additional technical results are shown in the Appendix.

\section{Preliminaries}
\subsection{Notation}
For this work, qubit indices start at zero, and start from the right. This means
$\ket{0010}$ is the result of applying an $X$ gate to qubit 1 of $\ket{0000}$.
Single-qubit rotation gates will be written with the rotation angle first, then
the qubit index. For example, an RZ gate, angle $\pi/2$, applied to qubit 1,
will be written as RZ($\pi/2$, 1). Control-X (CX) gates will be written with the
control qubit first. For example, a CX gate applied to qubit 2, with qubit 1 as
the control, will be written as CX(1, 2).
Unless otherwise specified, $n$ will represent the number of qubits in the
system, and $N = 2^n$ will represent the number of amplitudes to be encoded
onto those $n$ qubits.

\subsection{Quantum State Preparation Definition}
Quantum state preparation is formally defined as: Given an arbitrary quantum
state $\ket{x}$ and a family of quantum gates $G$, return a sequence of quantum
gates $g_1, g_2, ..., g_m$ from $G$ such that 
$g_mg_{m-1} ... g_1\ket{0} = \ket{x}$ \cite{1629135}.

In this paper, we assume $G$ contains continuously parameterized RX, RY, and RZ
gates, as well as the CX gate. This gate set was chosen
because these gates are both easy to reason about and easy to compile into
the native gate set of existing quantum computers \cite{maldonado2022error}.

In this work, we tackle the following version of the approximate quantum state
preparation problem: given an arbitrary quantum state $\ket{x}$, return a
sequence of quantum gates $g_1, g_2, ..., g_m$ such that
$$g_mg_{m-1} ... g_1\ket{x} = \ket{y}$$
And
$$|\braket{y|0}|^2 \geq 1 - \epsilon$$
Where $\epsilon$ represents a small error. The quantity $1 - \epsilon$ is
also known as the fidelity.

This version of approximate quantum state preparation can be applied towards
approximately preparing arbitrary quantum states. If for some state 
$\ket{x}$, a sequence of gates $g_1$, $g_2$, ..., $g_m$ can be found for
transforming $\ket{x}$ to $\ket{y}$, a state close to $\ket{0}$, then inverting
each gate and reversing the sequence generates a sequence of gates for 
approximately preparing $\ket{x}$ starting from $\ket{0}$.
If the gate sequence $g_m^{\dagger}$, $g_{m - 1}^{\dagger}$, ..., 
$g_1^{\dagger}$ was applied to $\ket{0}$ to achieve the state $\ket{x'}$, then
$$|\braket{x|x'}|^2 = |\bra{x}(g_1^{\dagger}g_2^{\dagger} ... g_m^{\dagger}\ket{0})|^2$$
$$ = |\braket{y|0}|^2 \geq 1 - \epsilon$$
Thus showing that the prepared state has a fidelity of $1 - \epsilon$.

\section{Proposed Algorithm, Formal Description}
In this work, we propose an approximate quantum state algorithm, which we call
``iterative sparse approximation" (ISA). Let the target
state be $\ket{x}$, and let $l$ be a list of quantum gates. Let the 
\textit{current state}, $\ket{c}$, be the state achieved by applying each gate 
in $l$ to $\ket{x}$. As the algorithm proceeds, gates will be added
to $l$. When the algorithm terminates, $l$ will be returned. 
The current state $\ket{c}$ starts out as $\ket{x}$ but becomes a 
state close to $\ket{0}$ by the end of the algorithm. Let $c_i$ denote
the amplitude at basis gate $\ket{i}$ in the current state, that is,
$$c_i = \braket{i|c}$$
The $\ket{c}$ and $c_i$ values are updated as gates are added to $l$.

The algorithm starts by using RZ and RY gates to bring the current state
closer to $\ket{0}$ (Refinement without CX gates), then iterates sparse 
approximations of the current state to bring the current state as close to 
$\ket{0}$ as needed (Refinement by ISA). The 
algorithm can be described by the pseudo-code:

\includegraphics[width=0.7\textwidth]{algo}

In the remainder of this section, we describe the details of the algorithm.
First, we show the sparse quantum state preparation methods to be adapted to
our algorithm. Next, we describe the details of refinement by RZ-RY. Then,
we elaborate on the method for selecting a sparse approximation in refinement
by ISA, before finishing with the method for adapting sparse quantum state
preparation for dense quantum states.

\subsection{Sparse Quantum State Preparation}
This work relies on the efficient preparation of two special types of sparse
quantum states. We enumerate these special states here, along with their
efficient preparation method. Our preparation methods presented here are
inspired by the methods presented in \cite{Malvetti2021quantumcircuits}.

The first type of special sparse quantum states, which we denote ``Type 1 sparse
states," contains exactly two non-zero
amplitudes. To prepare such states, first use a sequence of $RY(\pi)$ gates to
move one of the amplitudes to the $\ket{0}$ basis vector. Next, a sequence of
CX gates is used to move the other amplitude to a basis vector $\ket{a}$ such
that $a$ is a power of 2.
Finally, an RZ and an RY gate can be used to merge the two amplitudes together,
transforming the starting (target) state to $\ket{0}$. For example, if
$$\ket{x} = \frac{\sqrt{2}}{2}\ket{010} + \frac{\sqrt{2}}{2}i\ket{101}$$
First, $\text{RY}(\pi, 1)$ is applied to move 
$\frac{\sqrt{2}}{2}\ket{010}$ to the $\ket{000}$ position:
$$\text{RY}(\pi, 1) \ket{x} = \frac{\sqrt{2}}{2}\ket{000} 
- \frac{\sqrt{2}}{2}i\ket{111} := \ket{x_1}$$
Next, CX gates are applied to move the other amplitude to a basis vector
$\ket{a}$ such that $a$ has exactly one 1-bit in its binary representation. In
this case, we arbitrarily choose $a = 100$. Then, CX(1, 0) and
CX(2, 1) need to be applied in sequence to move $\ket{111}$ to $\ket{100}$.
$$\text{CX}(2, 1) \text{CX}(1, 0) \ket{x_1} = \frac{\sqrt{2}}{2}\ket{000} 
- \frac{\sqrt{2}}{2}i\ket{100} := \ket{x_2}$$
Next, an RZ gate is used to zero out the complex phase on $\ket{100}$:
$$\text{RZ}(\pi/2, 2)\ket{x_2} = \frac{\sqrt{2}}{2}\ket{000} 
+ \frac{\sqrt{2}}{2}\ket{100} := \ket{x_3}
\text{(ignoring global phase)}$$
Finally, an RY gate is used to merge the amplitudes together:
$$\text{RY}(-\pi/2, 2)\ket{x_3} = \ket{000}$$

The second type of special sparse quantum state, denoted ``Type 2 sparse states,"
are $n$-qubit states that can be written in the form:
\begin{equation} \label{type2sparse}
\ket{x} = (\ket{a_p} \otimes \ket{x_1} + \ket{0_p} \otimes \ket{x_2})
  \otimes \ket{0_q}
\end{equation}
Where $\ket{x_1}$ and $\ket{x_2}$ are arbitrary, non-normalized two-qubit states, $\ket{a_p}$ is
a nonzero $p$-bit basis state, $\ket{0_p}$ is a $p$-bit basis state,
$\ket{0_q}$ is a $q$-bit basis state ($q$ may be zero), and $p + q + 2 = n$.
Type 2 sparse states are those that can be written as the sum of two two-qubit
states and contain at most eight non-zero amplitudes.

To efficiently prepare such states, CX gates are first used to move $\ket{a}$ to
$\ket{1}$. The resultant quantum state will be a dense, three-qubit state,
which can be prepared exactly using three CX gates. Optimal, exact three-qubit
state preparation is well known in the literature \cite{PhysRevA.77.032320}; 
we describe our implementation in the Appendix.

\subsection{Refinement by RZ-RY}
First, the current state's maximal amplitude basis state, $\ket{b}$, is 
identified. While there is a qubit that does not yet have any gates applied to 
it, do:
\begin{enumerate}
	\item Collect the set of qubit indices that do not yet have any gates
		applied to them, call this set $I$.
	\item For each $i$ in $I$, compute $b_i$ as the result of flipping the 
		$i$th bit in $b$.
	\item Select $i$ such that $c_{b_i}$ is maximal.
	\item Compute $\theta_z = phase(c_b) - phase(c_{b_i})$. If 
		$b_i < b$, flip the sign of $\theta_z$.
	\item Compute $\theta_y = arctan(|\frac{c_b}{c_{b_i}}|)$. If
		$b_i < b$, flip the sign of $\theta_y$.
	\item Add RZ($\theta_z$, $i$) and RY($\theta_y$, $i$) to $l$, in that
		order. Update $\ket{c}$, and set $b \gets min(b, b_i)$
\end{enumerate}
Each time step 4 of the loop is run, the $i^*$th bit in $b$ is set to
$0$. Thus, at the end of this procedure, $b=0$, and the amplitude at $\ket{0}$
of the current state is at least as large as the largest amplitude in $\ket{x}$.

\subsection{Refinement by ISA: Selecting a sparse approximation}
To select a sparse approximation, each possible sparse approximation is
enumerated. Then, the \textit{fidelity increase ratio} is computed for each
candidate sparse approximation. Finally, the sparse approximation with the
largest fidelity increase ratio is selected.

\subsubsection{Type 1 sparse approximations}
During refinement by RZ-RY, the largest amplitude in the $\ket{x}$ was moved to 
$\ket{0}$ in $\ket{c}$. Thus, if $\ket{c}$ is to be approximated by a Type 1 
sparse state, one of the non-zero amplitudes is chosen to be $\ket{0}$. The 
other amplitude can be chosen freely. Thus, we index Type 1 sparse 
approximations by the other non-zero amplitude index:
$$\ket{x_1(i)} = c_0\ket{0} + c_i\ket{i}$$
The subscript 1 refers to Type 1 sparse approximation; the $i$ refers to the
index of the non-zero amplitude. In general, these sparse approximations are 
non-normalized states. The corresponding fidelity increase ratio is:
$$\text{fidelity increase ratio}(\ket{x_1(i)}) = \frac{|c_i|^2}{\alpha + 
\text{CXdist}(i)}$$
Where CXdist($i$) is the minimum number of CX gates required to transform 
$\ket{i}$ to $\ket{i'}$ such that $i'$ is a power of 2. This is also the number
of CX gates required to prepare $\ket{x_1(i)}$, as shown in section 4.1. The 
algorithm for computing
CXdist($i$) will be given in the Appendix.

The term $\alpha$ is a regularization term to prevent division by zero. For our
implementation, we set $\alpha = 1$.

\subsubsection{Type 2 sparse approximations}
Each Type 2 sparse state contains eight non-zero amplitudes; the indices of
those non-zero amplitudes are uniquely determined by $p$ and $a_p$ eqn. (\ref{type2sparse}). 
As with Type 1 sparse approximation, we index each candidate 
Type 2 sparse approximation by its non-zero amplitudes:
$$\ket{x_2(a, a_p)} = ((\ket{a_p}\bra{a_p} + \ket{0_p}\bra{0_p}) \otimes I \otimes I \otimes \ket{0_q}\bra{0_q})\ket{c}$$
In effect, $\ket{x_2(a, a_p)}$ is $\ket{c}$ but with all but the specified eight
amplitudes set to zero. Like Type 1 sparse approximations, the Type 2 sparse
approximations are generally non-normalized states.

For some non-normalized two-qubit states $\ket{\psi(a, a_p)_1}$, 
$\ket{\psi(a, a_p)_2}$. Then, the fidelity increase ratio can be computed as:
$$\text{fidelity increase ratio($a$, $a_p$)} = \frac{|\braket{x_2(a, a_p) | x_2(a, a_p)}|^2 - |c_0|^2}{\alpha + \text{CXdist}_1(a_p) + 3}$$
Where $\text{CXdist}_1(a)$ is the number of CX gates required to transform
$\ket{a}$ to $\ket{1}$. The plus three in the denominator accounts for the 
three CX gates required to perform the three-qubit quantum state preparation
base case, thus, $\text{CXdist}_1(a_p) + 3$ is the number of CX gates required
to prepare $\ket{x_2(a, a_p)}$. The algorithm for computing $\text{CXdist}_1$
will be given in the Appendix.

To choose a sparse approximation for the current state, all possible Type 1 and
Type 2 sparse approximations are considered and the approximation with the
largest fidelity increase ratio is selected.

\subsection{ISA: Adapting sparse approximation towards state preparation}
Once a sparse approximation $\ket{x'}$ is selected, the corresponding state 
preparation method is applied to $\ket{c}$ to bring it closer to $\ket{0}$.
\subsubsection{Type 1 sparse approximation}
If a Type 1 sparse approximation is selected, then the non-normalized sparse 
approximation takes the form
$\ket{c} \approx \ket{c'} = c_0\ket{0} + c_b\ket{b}$
for some $b$. The corresponding state preparation method moves $\ket{b}$ to a 
power of 2, then merges it with $\ket{0}$ using an RZ and an RY
gate. This is adapted to $\ket{c}$ by the following procedure:

While $b$ is not a power of 2, do:
\begin{enumerate}
	\item Enumerate all $b'$ such that $b' \neq b$ and there exists some CX gate that
		transforms $\ket{b}$ to $\ket{b'}$. Let the set of all such
		$b'$ be denoted $B$.
	\item For each $b'$ in $B$, calculate the move increase ratio as:
		$$\text{move increase ratio}(b')= \frac{|c_b|^2 + |c_{b'}|^2}{1 
        + min(\text{CXdist}(b), \text{CXdist}(b'))}$$
	\item Select $b^*$ from $B$ such that move increase ratio($b^*$) is
        maximal.
	\item If $\text{CXdist}(b) < \text{CXdist}(b^*)$, then merge the
		amplitudes at $\ket{b}$ and $\ket{b'}$ into $\ket{b}$ without 
		moving the amplitude at $\ket{0}$. Otherwise, merge the 
		amplitudes into $\ket{b^*}$ without moving the amplitude at 
		$\ket{0}$ and assign $b \leftarrow b^*$.
\end{enumerate}
After this loop terminates, merge the amplitudes at $\ket{b}$ and $\ket{0}$ 
into $\ket{0}$.

To merge the amplitudes at $\ket{a}$ and $\ket{b}$ into $\ket{b}$, without
moving the amplitude at $\ket{0}$, use the following procedure:
\begin{enumerate}
	\item For this merging to be possible, $a$ and $b$ must differ by
		exactly one bit in their binary representation. Let this
		difference be at position $i$. Also, let $c_a$ be the amplitude
		of the current state at $\ket{a}$ and let $c_b$ be the amplitude
		at $\ket{b}$. Also, $a$ and $b$ must both have a $1$ adjacent to
		position $i$ in their binary representation, let this position
		be $j$.
	\item Compute $\theta_z = phase(c_b) - phase(c_a)$. If $a < b$, flip the
		sign of $\theta_z$.
	\item Compute $\theta_y = arctan(|\frac{c_b}{c_a}|)$. If $a < b$, flip
		the sign of $\theta_y$.
	\item Add RZ($\theta_z$, $i$), RY($\theta_y$, $i$), CX($j$, $i$), and
		RY($-\theta_y$, $i$), in that order, to $l$ and update 
		$\ket{c}$.
\end{enumerate}
This procedure usually changes the complex phase of $c_0$, but this is
inconsequential towards the algorithm.

To merge the amplitude at $\ket{b}$ into $\ket{0}$, the method from refinement
by RZ-RY can be applied.

\subsection{Implementing a Type 2 sparse approximation}
If a Type 2 sparse approximation is selected, then the sparse approximation
takes the form:
$$\ket{c} \approx \ket{c'} = (\ket{a_p} \otimes \ket{x_a} + 
  \ket{0_p} \otimes \ket{x_0}) \otimes \ket{0_q}$$
Where $\ket{x_a}$ and $\ket{x_0}$ are non-normalized two-qubit states.
Define $\ket{x_i}$ as:
$$\ket{x_i} = (\ket{i}\bra{i} \otimes I \otimes I \otimes \ket{0_q}\bra{0_q})\ket{c}$$ 
The sparse state preparation method for Type 2 sparse approximations moves 
$\ket{a}$ to $\ket{1}$, then use three-qubit state preparation to merge 
$\ket{1} \otimes \ket{x_1}$ into $\ket{0} \otimes \ket{x_0}$. This method can be
adapted to $\ket{c}$ by the following procedure.
\begin{enumerate}
	\item Enumerate all $a'$ such that $a \neq a'$ and $\ket{a}$ can be 
        transformed to $\ket{a'}$ by applying a CX gate; let the set of all such
        $a'$ be denoted $A$.
	\item For each $a'$ in $A$, compute its move increase ratio as:
		$$\text{move increase ratio}(a') = \frac{\frac{1}{2}(\braket{x_{a'} | x_{a'}}) 
        + \frac{1}{2}\sqrt{(\braket{x_{a'}|x_{a'}} 
        - \braket{x_a|x_a})^2 + 4|\braket{x_a'|x_a}|^2}}
        {3 + min(\text{CXdist}_1(a), \text{CXdist}_1(a'))}$$
        The numerator represents the magnitude of $\ket{x_a'}$ after
        approximately merging $\ket{a}$ into $\ket{a'}$; the denominator
        represents one CX gate used to perform this merging plus the number of
        CX gates remaining in the implementation of this sparse approximation.
	\item Select $a^*$ to be the element of $A$ with the largest
		fidelity increase ratio
	\item If $\text{CXdist}_1(a) < \text{CXdist}_1(a^*)$, then merge 
		$\ket{a^*} \otimes \ket{x_{a^*}}$ into $\ket{a} \otimes \ket{x_a}$ while
        leaving $\ket{0} \otimes \ket{x_0}$ unchanged. Otherwise, merge 
        $\ket{a} \otimes \ket{x_a}$ into $\ket{a^*} \otimes \ket{x_{a*}}$
		and assign $a \leftarrow a^*$.
\end{enumerate}
After the loop terminates, $a = 1$, and the three-qubit state preparation
procedure can be used to merge $\ket{a}$ into $\ket{0}$.

Merging $\ket{a} \otimes \ket{x_a}$ into $\ket{b} \otimes \ket{x_b}$
while leaving $\ket{0} \otimes \ket{x_0}$ unchanged usually cannot be done 
exactly using three or fewer CX gates. Therefore, in our implementation, we
perform this merging only approximately. In addition, this can be done only
if $\ket{a}$ can be transformed to $\ket{b}$ using some CX gate, CX($i$, $j$).
Then, approximate merging is implemented by the following procedure:
\begin{enumerate}
    \item If $a < b$, let $\ket{v_0} = \ket{x_a}$ and $\ket{v_1} = \ket{x_b}$.
    Otherwise, let $\ket{v_1} = \ket{x_a}$ and $\ket{v_0} = \ket{x_b}$.
    \item Compute $\theta_z = -phase(\braket{v_0|v_1})$.
    \item Compute $\theta_y = \frac{1}{2}\left(-\pi - arccos\Bigl(\frac{\braket{v_0 | v_0}
      - \braket{v_1 | v_1}}{2\sqrt{(\braket{v_0 | v_0} - \braket{v_1 | v_1})^2
      + |\braket{v_0 | v_1}|^2}}\Bigr)\right)$
    \item Add RZ($\theta_z$, $j$), RY($\theta_y$, $j$), CX($i$, $j$), and
      RY($-\theta_y$, $j$) to $l$ and update $\ket{c}$.
\end{enumerate}

\section{Numerical Experiments: CX count and computation time on random dense states}
\subsection{Method}
We compare our ISA method against the exact state preparation method using
uniformly controlled gates (UCG) \cite{bergholm2005quantum}, alternating ansatz
VQC \cite{zhang2020toward}, and ADAPT-VQE \cite{grimsley2019adaptive} methods.
All
experiments were performed assuming the linear nearest neighbors architecture;
for the proposed method and variational methods, the target state preparation
fidelity was set to 0.95. For the variational methods, simple gradient descent
was used, with $1 - fidelity$ as the cost function, and a constant learning
rate of 0.1. For ADAPT-VQE, initialized the circuit to contain a layer of RY
rotations, followed by a layer of RZ rotations. For the operator pool, we used 
the following circuit block, translated across different possible positions:

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{adapt_block}
\caption{\textit{The circuit block used in ADAPT-VQE for state preparation. The operator
pool is generated by translating this block across different pairs of qubits.}}
\end{figure}

In addition, we modified the ADAPT-VQE procedure. Instead of comparing gradient
sizes to choose an operator, we performed 30 gradient descent steps for each
candidate operator and selected the candidate that gave the best
improvement. Then, after adding that operator, the entire gate sequence was
trained for 200 additional steps. 

The implementation of the UCG method
was taken from the Python package \textit{qclib} \cite{Araujo_Quantum_computing_library_2023}. All other methods were 
implemented from scratch in C++. 

In our experiments, we tested the number of CX gates used and the computation
time as a function of number of qubits in the target state. We tested qubit
numbers from 5 to 14, inclusive. For each qubit number, 100 quantum states were
uniformly, randomly sampled.

For the runtime experiments, the number of CX gates in the alternating
ansatz VQC was set to $2^{n - 1}$. This number was specifically chosen
because each CX gate attaches four free parameters, therefore, approximately
$2^{n - 1}$ CX gates are necessary for the number of circuit parameters to
exceed the number of free parameters in an $n$-qubit quantum state. Under these
conditions, the VQC should be able to prepare any arbitrary $n$-qubit quantum 
state with high fidelity.

To determine the number of training iterations needed for alternating ansatz 
VQC, we trained VQC's with varying numbers of layers, and report the CX gate 
count corresponding to the minimum number of layers needed to achieve an average
fidelity of 0.95. However, this minimum CX count also depends on the number of 
gradient descent steps used to optimize the angles: more layers requires less
training. To ensure a sufficiently large but also fair number of training 
iterations for each $n$, we trained an
alternating ansatz with $\frac{1}{2}2^n$ CX gates on the first three random
quantum states and recorded the number of training iterations required to
achieve 0.95 fidelity on all three states. Then, the number of training
iterations was set to the sum of those numbers multiplied by two. This ensured
that the number of training iterations was approximately six times as many as
actually necessary for that specific number of qubits, preventing insufficient
training from marring the results.

Finally, CX gate count experiments were not run for the uniformly controlled 
gates method. This is because the number of gates for this exact method depends
on the transpiler, sometimes finding good optimizations for the
linear nearest neighbor architecture, sometimes failing to. However, using the
exact nature of this algorithm, it was determined that this method uses
$2\times 2^n + 2n - 19$ CX gates to prepare an $n$-qubit quantum state (proof given in the Appendix). 

\subsection{Results}
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{Timing.png}
\caption{\textit{Total runtime versus number of qubits for each quantum state
preparation method, plotted on a linear-log scale. Only the ISA and UCG methods
were able to prepare the quantum states for $n$ up to 14; the alternating
ansatz method timed out after $n = 9$ and the ADAPT-VQE method timed out after
$n = 7$. In addition, while the ISA method starts out much faster than the UCG
method, the UCG curve has a lower slope than the ISA method, indicating that for
larger $n$, UCG is probably faster than ISA.}}
\label{fig:timing_figure}
\end{figure}

Figure \ref{fig:timing_figure} shows the runtime versus number of qubits curve for each method. For 
all numbers of qubits tested, the iterated sparse approximation method had the 
lowest runtime, however, the ISA method's runtime increases faster with
qubit number compared to the UCG method. Thus, the UCG method is expected to
be faster than ISA for more than 14 qubits; both methods were orders of
magnitude faster than the variational methods. This reflects the intense
computational cost incurred by rotation angle optimization procedure.

\begin{table}
\begin{tabular}{c | c | c | c | c}
  \textbf{Number of qubits} & \textbf{ISA} & \textbf{UCG} & \textbf{ADAPT-VQE} & \textbf{VQC} \\
  \hline
  5 & 24.08 & 55 & 13.67 & 14 \\
  6 & 60.98 & 121 & 25.97 & 28 \\
  7 & 143.46 & 251 & 47.96 & 48 \\
  8 & 319.02 & 509 & 88.76 & 91 \\
  9 & 689.32 & 1023 & 164.22 & 180 \\
  10 & 1439.6 & 2049 & TIMEOUT & TIMEOUT \\
  11 & 2952.66 & 4099 & & \\
  12 & 5991.51 & 8197 & & \\
  13 & 12123.3 & 16391 & & \\
  14 & 24538 & 32777 & & \\
\end{tabular}
\caption{\textit{Average number of CX gates used to prepare 100
randomly generated quantum states versus number of qubits. Therefore, the values
in the ISA and ADAPT-VQE column show two decimal digits. By contrast, the values
for the UCG column were calculated, and are therefore whole numbers. In
addition, the values for VQC, alternating ansatz were calculated by finding
the minimum number of CX gates corresponding to an average fidelity of 0.95 - 
these are also whole numbers}}
\end{table}

Table 1 shows the average number of CX gates used by each method as a function
of the number of qubits. The UCG method uses the most CX gates; the ISA method
uses somewhat fewer CX gates, while the variational methods use the fewest
CX gates. The variational methods far outperform the non-variational methods
in this regard, demonstrating the effectiveness of the variational optimization
procedure. That said, the ISA method is shown to outperform the UCG method
without any variational angle tuning procedure, indicating that iterative sparse
approximation is able to directly find good quantum state preparation gate
sequences.

The number of free parameters in the quantum circuit is proportional to the
number of CX gates; the number of free parameters needed is proportional to
$N = 2^n$, the number of complex amplitudes in the target state. Therefore, we
hypothesized that the number of CX gates would be approximately proportional
to $N$ and try to determine the constant factor by graphing CX count divided by
$N$ as a function of the number of qubits. If the CX count is indeed
proportional to $N$, then the graph should approach a horizontal line for large
$n$, with its asymptote being the constant factor.

\begin{figure}[H]
\includegraphics[width=0.8\textwidth]{CX_n}
\caption{\textit{Average number of CX gates divided by $N$ versus number of qubits for
each quantum state preparation method. The curve for VQC and ADAPT-VQE methods
are truncated because these methods timed out for larger numbers of qubits. The
curve for UCG is a nearly horizontal line at constant factor 2, reflecting the
CX count formula for the UCG method. The curve for ISA starts out quite low but
increases to around 1.5. The VQC and ADAPT-VQE curves stay quite low,
approaching 0.3, but the curves are truncated due to timeout.}}
\label{fig:CX_n}
\end{figure}

Figure \ref{fig:CX_n} shows the average number of CX gates divided by N as a function of
qubit number for each method. For the ISA method, the curve increases for 
$n < 10$, then stabilizes to around 1.5. Thus, we conclude that the ISA method
will use approximately 1.5$N$ CX gates for randomly sampled quantum states.
By contrast, the UCG method is shown to use $2N + 2n - 19$, which is 2$N$ to
leading order. Thus, the ISA method is shown to use approximately 25\% fewer
CX gates compared to the UCG method. However, both variational methods
stabilize to around 0.3, which is about 5 times better than ISA, demonstrating
the effectiveness of the variational tuning procedure.

\section{Discussion and Conclusion}
The ISA algorithm presented has been shown to use fewer CX gates than exact
state preparation methods without incurring the variational optimization costs
associated with VQC algorithms. However, the VQC methods are able to prepare
quantum states using much fewer CX gates compared to the ISA method, and the 
UCG method is expected to be faster than ISA for quantum states on more than 14
qubits. This trend is expected: the less computation time a method uses, the
lower the quality of its output.

In practice, every CX gate applied introduces hardware noise into the
computation. Therefore, the design of quantum circuits will require a careful
balance between using enough CX gates to approximate the desired computation,
while not using so many CX gates as to corrupt the computation with noise.
The ISA algorithm lends itself to a simple method for finding this balance:
if too many CX gates are present in the state preparation algorithm, simply
delete the gates corresponding to the last iterative sparse approximation; if
insufficient CX gates are present, perform more sparse approximation iterations.
This works because each iteration of sparse approximation monotonically
increases the state preparation fidelity, and each additional iteration provides
diminishing returns on fidelity increase. By contrast, applying such a procedure
towards simple VQC would require re-training the quantum circuit depending on
the number of ansatz layers used. For large numbers of qubits, this would incur
significantly more computational costs.

In addition, different quantum hardwares have different qubit connectivities.
The only hardware-dependent steps in the ISA algorithm are enumerating the list
of available CX gates and computing CXdist, $\text{CXdist}_1$. The former is
derived directly from the hardware connectivity; the latter can be efficiently
pre-computed from the list of available CX gates using the worklist algorithm.

However, the ISA method does face several limitations. Most importantly, the ISA
methods uses four or five times as many CX gates as the VQC methods. This may
will cause ISA-generated gate sequences to induce much more noise on near term
quantum hardware compared to VQC-based methods. This problem may eventually be
mitigated by future work discovering alternative, easy-to-prepare classes of 
quantum states for approximating dense quantum states, then adapting those
discoveries towards improving the ISA algorithm. In addition, it may be possible
to incorporate some variational training alongside ISA. However, the cost 
function, training schedule, gradient conditioning, and other things
would need to be carefully designed to ensure such a hybrid method doesn't 
become a worse version of ADAPT-VQE or pure VQC. 

Another limitation of the ISA method is that it cannot prepare quantum states
that require extremely high fidelity. This is because, at each iteration, the
ISA method treats the dense target state as a sparse approximate state.
Therefore, some percentage of the fidelity will be lost on every iteration of
the sparse approximation, and chasing down these lost details will require many,
many more iterations of ISA, leading to extremely long gate sequence. That said,
many applications of quantum state preparation, such as machine learning and 
probability distribution function sampling, require only approximate quantum
state preparation.

To conclude, we present a non-variational framework for approximate quantum 
state preparation by iteratively applying sparse quantum state preparation
methods. The non-variational nature of our framework resulted in orders of
magnitude speedup compared to variational approaches. In addition, the ISA
method was able to prepare quantum states with 95\% fidelity, using 25\% 
fewer CX gates compared to the UCG exact method on linear nearest neighbor 
architectures, demonstrating its ability to find good state preparation 
sequences. Future work may investigate closing the gap in CX gate count between
the ISA method and VQC-based methods, perhaps by adapting more advanced sparse
state preparation techniques or by selectively integrating variational tuning
procedures. Still, the advantages of our method have been demonstrated.

\section{Appendix}

\subsection{Optimal, exact three-qubit state preparation}
Optimal, exact three-qubit quantum state preparation has been studied in the
literature \cite{PhysRevA.77.032320}; our specific implementation requires
three steps, called ``D1", ``D2", and ``SP2."

Let the target state be:
$$\ket{x} = \sum_{i, j, k \in {0, 1}}{a_{ijk}\ket{ijk}}$$

Step D1 applies a single-qubit rotation, then CX(0, 1), then another
single-qubit rotation to $\ket{x}$, resulting in the state
$$\ket{y} = \sum_{i, j, k \in {0, 1}}{b_{ijk}\ket{ijk}}$$
Such that
$$\frac{b_{110}}{b_{010}} = \frac{b_{111}}{b_{011}} 
  \text{ and } \frac{b_{100}}{b_{000}} = \frac{b_{101}}{b_{001}}$$

Next, step D2 uses a single-qubit rotation, CX(1, 2), and another 
single-qubit rotation to transform $\ket{y}$ into a two-qubit state:
$$\ket{z} = \sum_{j, k \in {0, 1}}{c_{jk}\ket{0jk}}$$.

Finally, step SP2 implements two-qubit state preparation on this state using
one CX gate and several single-qubit rotations. We describe each of these steps
in detail, starting with SP2 and D2. Then, we briefly discuss the
decomposition of uniformly controlled single-qubit rotations before concluding
with a description of D1.

\subsubsection{SP2}
Starting from the state
$$\ket{z} = \sum_{j, k \in {0, 1}}{c_{0jk}\ket{0jk}}$$
We apply an RZ and RY gate to qubit 0 to merge $c_{001}\ket{001}$ into 
$c_{000}\ket{000}$
using the method from section 4.4.1 of the main text, leading to the state:
$$\ket{z'} = c'_{000}\ket{000} + c'_{010}\ket{010} + c'_{011}\ket{011}$$
Next, an RZ, RY, CX, and RY gate sequence is used to merge $c'_{011}\ket{011}$
into $c'_{010}\ket{010}$ without moving $c'_{000}\ket{000}$, using the
method described in section 4.4.1 of the main text. This results in a one-qubit
state that can be prepared using a single qubit rotation gate.

\subsubsection{D2}
Starting from the state
$$\ket{y} = \sum_{i, j, k \in \{0, 1\}}{b_{ijk}\ket{ijk}}$$
We apply an RZ and RY gate to qubit 2 to merge $b_{100}\ket{100}$ into 
$b_{000}\ket{000}$, using the same method as in SP2. The pre-condition:
$$\frac{b_{100}}{b_{000}} = \frac{b_{101}}{b_{001}}$$
Implies that this procedure also merges $b_{101}\ket{101}$ into 
$b_{001}\ket{001}$. This results in the state:
$$\ket{y'} = \sum_{i, j, k \in \{0, 1\}}{b'_{ijk}\ket{ijk}} \quad \quad \quad \quad \quad b'_{100}, b'_{101} = 0$$
In addition, the RZ and RY gate were applied to
qubit 2, therefore, the equality
$$\frac{b_{110}}{b_{010}} = \frac{b_{111}}{b_{011}}$$
Is preserved after this transformation:
$$\frac{b'_{110}}{b'_{010}} = \frac{b'_{111}}{b'_{011}}$$
Next, an RZ, RY, CX, RY sequence is used to merge $b'_{110}\ket{110}$ into
$b'_{010}\ket{010}$ without moving $b'_{000}\ket{000}$, using the same method as
in SP2. The equality
$$\frac{b'_{110}}{b'_{010}} = \frac{b'_{111}}{b'_{011}}$$
Ensures that $b'_{111}\ket{111}$ is also merged into $b'_{011}\ket{011}$ by this
process. The single qubit rotations are applied to qubit 2 and the CX gate is
applied to qubits 1 and 2. Therefore, this operation acts independently of
qubit 0. Therefore, $b'_{001}\ket{001}$ is unmoved.

The previous step zeroed out the $\ket{100}$ and $\ket{101}$ basis vectors; this
step zeroed out the $\ket{110}$ and $\ket{111}$ basis vector.s Therefore, the
result of these transformations is a two-qubit state:
$$\ket{z} = \sum_{j, k \in \{0, 1\}}{c_{jk}\ket{0jk}}$$

\subsubsection{Decomposing uniformly single controlled single-qubit rotations}
In this section, we describe the set of uniformly controlled single-qubit
rotations with one control qubit that can be decomposed into one CX gate and
single-qubit rotations. In addition, we give a procedure for their 
decomposition. These constructions will be necessary for the construction of
step D1 for optimal, exact three-qubit state preparation.

For simplicity, let the control qubit be qubit 1, let the target qubit be qubit
0. Suppose the desired gate applies $a$ if the control qubit is $0$, applies $b$
otherwise. Then the desired gate has matrix form:
$$\begin{bmatrix}
a&0\\
0&b
\end{bmatrix}$$
We wish to decompose this transformation into a quantum circuit of the form:

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{ucg_single}
\caption{\textit{Target decomposition of the uniformly controlled, single-qubit rotation with one control qubit}}
\end{figure}

These gates, together, take the matrix form:
$$\begin{bmatrix}v&0\\0&v\end{bmatrix}
\begin{bmatrix}I&0\\0&X\end{bmatrix}
\begin{bmatrix}u&0\\0&u\end{bmatrix}$$

This requires some $u$ and $v$ to exist, such that $a = vu$ and $b = vXu$. Then
$$ab^\dagger = (vu)(vXu)^\dagger = vXv^\dagger$$
Which implies that $ab^\dagger$ must have the same eigenvalues, $\pm 1$, as $X$.
This condition is both necessary and sufficient for the uniformly controlled
rotation to be decomposable into the quantum circuit shown. Indeed, if 
$ab^\dagger$ has the same eigenvalues as $X$, then we can compute $v$ by 
diagonalization, then compute $u = v^\dagger a$. Finally, $u$ and $v$ can be
decomposed to RY and RZ gates using ZYZ decomposition \cite{1629135}.

\subsubsection{Implementing D1}
Step D1 is implemented using a uniformly controlled single-qubit rotation, with
qubit 0 as the control, qubit 1 as the target. To implement D1, we construct
single-qubit operations $a$ and $b$ such that applying 
$\begin{bmatrix}a&0\\0&b\end{bmatrix}$ leads to the state 
$$\ket{y} = \sum_{i, j, k \in \{0, 1\}}{b_{ijk}\ket{ijk}}$$
Such that
$$\frac{b_{110}}{b_{010}} = \frac{b_{111}}{b_{011}} 
  \text{ and } \frac{b_{100}}{b_{000}} = \frac{b_{101}}{b_{001}}$$
In addition, we perform this construction such that $ab^\dagger$ has eigenvalues
$\pm 1$ to ensure the transformation can be implemented using only one CX gate.

We parameterize $a$ and $b$ as:
$$a = e^{i\phi_g}\begin{bmatrix}cos(\theta_a)&-sin(\theta_a)e^{i\phi_a}\\
  sin(\theta_a)e^{i\alpha_a}&cos(\theta_a)e^{i(\alpha_a + \phi_a)}\end{bmatrix}$$
$$b = \begin{bmatrix}cos(\theta_b)&-sin(\theta_b)e^{i\phi_b}\\
  sin(\theta_b)e^{i\alpha_b}&cos(\theta_b)e^{i(\alpha_b + \phi_b)}\end{bmatrix}$$

Then, we can express the $b_{ijk}$ coefficients of $\ket{y}$ in terms of 
$\phi_g$, $\theta_a$, $\alpha_a$, $\phi_a$, $\theta_b$, $\alpha_b$, $\phi_b$, 
and the $a_{ijk}$ coefficients of $\ket{x}$:

$$b_{000} = e^{i\phi_g}(cos(\theta_a)a_{000} + sin(\theta_a)e^{i\phi_a}a_{010})$$
$$b_{010} = e^{i(\alpha_a + \phi_g)}(-sin(\theta_a)a_{000} + cos(\theta_a)e^{i\phi_a}a_{010})$$
$$b_{100} = e^{i\phi_g}(cos(\theta_a)a_{100} + sin(\theta_a)e^{i\phi_a}a_{110})$$
$$b_{110} = e^{i(\alpha_a + \phi_g)}(-sin(\theta_a)a_{100} + cos(\theta_a)e^{i\phi_a}a_{110})$$
$$b_{001} = cos(\theta_b)a_{001} + sin(\theta_b)e^{i\phi_b}a_{011}$$
$$b_{011} = e^{i\alpha_b}(-sin(\theta_b)a_{001} + cos(\theta_b)e^{i\phi_b}a_{011})$$
$$b_{101} = cos(\theta_b)a_{101} + sin(\theta_b)e^{i\phi_b}a_{111}$$
$$b_{111} = e^{i\alpha_b}(-sin(\theta_b)a_{101} + cos(\theta_b)e^{i\phi_b}a_{111})$$

Then the constraints
$$\frac{b_{110}}{b_{010}} = \frac{b_{111}}{b_{011}} 
  and \frac{b_{100}}{b_{000}} = \frac{b_{101}}{b_{001}}$$
Can be written as:

$$\frac{e^{i(\alpha_a + \phi_g)}(-sin(\theta_a)a_{100} + cos(\theta_a)e^{i\phi_a}a_{110})}{e^{i(\alpha_a + \phi_g)}(-sin(\theta_a)a_{000} + cos(\theta_a)e^{i\phi_a}a_{010})} = 
\frac{e^{i\alpha_b}(-sin(\theta_b)a_{101} + cos(\theta_b)e^{i\phi_b}a_{111})}{e^{i\alpha_b}(-sin(\theta_b)a_{001} + cos(\theta_b)e^{i\phi_b}a_{011})}$$
$$\frac{e^{i\phi_g}(cos(\theta_a)a_{100} + sin(\theta_a)e^{i\phi_a}a_{110})}{e^{i\phi_g}(cos(\theta_a)a_{000} + sin(\theta_a)e^{i\phi_a}a_{010})} = \frac{cos(\theta_b)a_{101} + sin(\theta_b)e^{i\phi_b}a_{111}}
{cos(\theta_b)a_{001} + sin(\theta_b)e^{i\phi_b}a_{011}}$$

Note that the $e^{i\alpha_a}$, $e^{i\alpha_b}$, $e^{i\phi_g}$ terms cancel out,
making $\phi_g$, $\alpha_a$, and $\alpha_b$ free parameters. Multiplying out
the denominators, dividng by $cos(\theta_a)cos(\theta_b)$, and re-arranging the
terms gives:

$$Atan(\theta_a)tan(\theta_b) + Btan(\theta_a)e^{i\phi_b} + Ctan(\theta_b)e^{i\phi_a} + De^{i(\phi_a + \phi_b)} = 0$$
$$A - Btan(\theta_b)e^{i\phi_b} - Ctan(\theta_a)e^{i\phi_a} + Dtan(\theta_a)tan(\theta_b)e^{i(\phi_a + \phi_b)} = 0$$

Where
$$A = a_{100}a_{001} - a_{000}a_{101}$$
$$B = a_{100}a_{011} - a_{000}a_{111}$$
$$C = a_{110}a_{001} - a_{010}a_{101}$$
$$D = a_{110}a_{011} - a_{010}a_{111}$$

Dividng the first equation by $e^{i(\phi_a + \phi_b)}$ and taking its conjugate
results in the following system of equations:
$$A^*tan(\theta_a)tan(\theta_b)e^{i(\phi_a + \phi_b)} + B^*tan(\theta_a)e^{i\phi_a} + C^*tan(\theta_b)e^{i\phi_b} + D^* = 0$$
$$A - Btan(\theta_b)e^{i\phi_b} - Ctan(\theta_a)e^{i\phi_a} + Dtan(\theta_a)tan(\theta_b)e^{i(\phi_a + \phi_b)} = 0$$

Performing the substitution:
$$x = tan(\theta_a)e^{i\phi_a}$$
$$y = tan(\theta_b)e^{i\phi_b}$$

Results in the system of equations:
$$A^*xy + B^*x + C^*y + D^* = 0$$
$$A - By - Cx + Dxy = 0$$

Which can be easily solved by substitution. Once $x$ and $y$ are known, 
$\theta_a$, $\theta_b$, $\phi_a$, $\phi_b$ can be determined.

Next, the constraint on the eigenvalues of $ab^\dagger$ needs to be satisfied.
Using the same parameterization as before, we can write:
$$a = e^{i\phi_g}\begin{bmatrix}cos(\theta_a)&-sin(\theta_a)e^{i\phi_a}\\
  sin(\theta_a)e^{i\alpha_a}&cos(\theta_a)e^{i(\phi_a + \alpha_a)}\end{bmatrix}
  = e^{i\phi_g}\begin{bmatrix}1&0\\0&e^{i\alpha_a}\end{bmatrix}\begin{bmatrix}
  cos(\theta_a)&-sin(\theta_a)e^{i\phi_a}\\sin(\theta_a)&cos(\theta_a)e^{i\phi_a}\end{bmatrix}$$
$$b = \begin{bmatrix}cos(\theta_b)&-sin(\theta_b)e^{i\phi_b}\\
  sin(\theta_b)e^{i\alpha_b}&cos(\theta_b)e^{i(\phi_b + \alpha_b)}\end{bmatrix}
  = \begin{bmatrix}1&0\\0&e^{i\alpha_b}\end{bmatrix}\begin{bmatrix}cos(\theta_b)
  &-sin(\theta_b)e^{i\phi_b}\\sin(\theta_b)&cos(\theta_b)e^{i\phi_b}\end{bmatrix}$$

$$ab^\dagger = e^{i\phi_g}\begin{bmatrix}1&0\\0&e^{i\alpha_a}\end{bmatrix}\left(
  \begin{bmatrix}cos(\theta_a)&-sin(\theta_a)e^{i\phi_a}\\
  sin(\theta_a)&cos(\theta_a)e^{i\phi_a}\end{bmatrix}\begin{bmatrix}
  cos(\theta_b)&-sin(\theta_b)e^{i\phi_b}\\sin(\theta_b)
  &cos(\theta_b)e^{i\phi_b}\end{bmatrix}^\dagger\right)\begin{bmatrix}1&0\\
  0&e^{i\alpha_b}\end{bmatrix}^\dagger$$

The two matrices between the parentheses are unitary matrices, thus, their
product is a unitary matrix and can be expressed as:
$$\begin{bmatrix}cos(\theta_a)&-sin(\theta_a)e^{i\phi_a}\\
  sin(\theta_a)&cos(\theta_a)e^{i\phi_a}\end{bmatrix}\begin{bmatrix}
  cos(\theta_a)&-sin(\theta_a)e^{i\phi_a}\\sin(\theta_a)
  &cos(\theta_a)e^{i\phi_a}\end{bmatrix}^\dagger = 
  e^{i\alpha_g}\begin{bmatrix}cos(\theta)&-sin(\theta)e^{i\phi}\\
  sin(\theta)e^{i\alpha}&cos(\theta)e^{i(\alpha + \phi)}\end{bmatrix}$$
For some $\alpha_g$, $\alpha$, $\phi$, and $\theta$. Then, we can write
$$ab^\dagger = e^{i\phi_g}\begin{bmatrix}1&0\\0&e^{i\alpha_a}\end{bmatrix}
  e^{i\alpha_g}\begin{bmatrix}cos(\theta)&-sin(\theta)e^{i\phi}\\
  sin(\theta)e^{i\alpha}&cos(\theta)e^{i(\alpha + \phi)}\end{bmatrix}
  \begin{bmatrix}1&0\\0&e^{i\alpha_b}\end{bmatrix}^\dagger$$
$$ = e^{i(\phi_g + \alpha_g)}\begin{bmatrix}cos(\theta)&-sin(\theta)
  e^{i(\phi - \alpha_b)}\\sin(\theta)e^{i(\alpha + \alpha_a)}
  &cos(\theta)e^{i(\phi + \alpha + \alpha_a - \alpha_b)}\end{bmatrix}$$

The characteristic polynomial of this matrix is:
$$p(t) = (cos(\theta)e^{i(\phi_g + \alpha_g)} - t)
(cos(\theta)e^{i(\phi + \alpha + \alpha_a - \alpha_b + \phi_g + \alpha_g)} - t)$$
$$- (-sin(\theta)e^{i(\phi - \alpha_b + \phi_g + \alpha_g)})
  (sin(\theta)e^{i(\alpha - \alpha_a + \phi_g + \alpha_g)})$$
$$ = t^2 - e^{i(\phi_g + \alpha_g)}cos(\theta)(1 + e^{i(\phi + \alpha + \alpha_a - \alpha_b)})t 
  + cos(\theta)^2e^{i(2(\phi_g + \alpha_g) + \phi + \alpha + \alpha_a - \alpha_b)} $$
  $$+ sin(\theta)^2e^{i(2(\phi_g + \alpha_g) + \phi + \alpha + \alpha_a - \alpha_b)}$$
$$ = t^2 - e^{i(\phi_g + \alpha_g)}cos(\theta)(1 + e^{i(\phi + \alpha + \alpha_a - \alpha_b)})t + e^{2i(\phi_g + \alpha_g)}e^{i(\phi + \alpha + \alpha_a - \alpha_b)}$$

We require the eigenvalues to be $\pm 1$, so the characteristic polynomial must
be equal to $t^2 - 1$. This requires:
$$e^{i(\phi_g + \alpha_g)}cos(\theta)(1 + e^{i(\phi + \alpha + \alpha_a - \alpha_b)}) = 0$$
$$e^{2i(\phi_g + \alpha_g)}e^{i(\phi + \alpha + \alpha_a - \alpha_b)} = -1$$
Solving these equations gives:
$$\phi + \alpha + \alpha_a - \alpha_b = \pi$$
$$\phi_g + \alpha_g = 0$$
Therefore, we set $\phi_g = -\alpha_g$, $\alpha_a = \pi - \phi - \alpha$, and
$\alpha_b = 0$ to ensure that $ab^\dagger$ is similar to $X$. Now, all the
parameters in $a$ and $b$ are specified, and the procedure from the previous
section can be used to compute the gate sequence implementing the desired
transformation. This concludes the description of each individual step in our
linear nearest neighbors implementation of optimal, exact three-qubit state
preparation.

\subsection{Computing CXdist and $\text{CXdist}_1$}
We first show how to compute $\text{CXdist}_1$ for linear nearest neighbor
architecture. For each integer $x$, define:
$$top(x) = max(i), \textit{ s.t. } 2^i \leq x$$
$$holes(x) = |\{0 \leq k \leq top(x) \text{ and } x >> k \text{ is even}\}|$$
If $x$ is written in its binary representation, then $top(x)$ is the largest
position where $x$ has a 1, and $holes(x)$ is the number of zeroes to the right
of position $top(x)$ in $x$.

We claim that $\text{CXdist}_1(x) = top(x) + holes(x)$. To prove that this is 
the case, we show that
\begin{enumerate}
    \item It is always possible to transform $\ket{x}$ to $\ket{1}$ using 
      $top(x) + holes(x)$ CX gates.
    \item If a CX gate transforms $\ket{x}$ to $\ket{x'}$, then
      $$top(x') + holes(x') \geq top(x) + holes(x) - 1$$
\end{enumerate}
The second point shows that the quantity $top(x) + holes(x)$ decreases by at
most 1 for each CX gate, therefore it takes at least $top(x) + holes(x)$ CX
gates to transform $\ket{x}$ to a state $\ket{x'}$, where 
$top(x') + holes(x') = top(1) + holes(1) = 0$. This implies 
$\text{CXdist}_1(x) \geq top(x) + holes(x)$. Taken together with the first
statement, they together imply the claim that 
$\text{CXdist}_1(x) = top(x) + holes(x)$.

To prove the first statement, we construct a list $l$ of CX gates that
transforms $\ket{x}$ to $\ket{1}$. 
Let $\ket{c}$ be the state achieved after applying each gate in $l$ to
$\ket{x}$. At the start, $\ket{c} = \ket{x}$; at the end, $\ket{c} = \ket{1}$.
Construct $l$ as follows:
\begin{enumerate}
    \item For $i$ in $[top(x), top(x) - 1, ..., 1]$, if the $i - 1$th bit in 
	    $\ket{c}$ is
      zero, then add CX($i$, $i - 1$) to $l$ and update $\ket{c}$. Otherwise do
      nothing.
    \item For $i$ in $[top(x), top(x) - 1, ..., 1]$, add CX($i - 1$, $i$) to
      $l$ and update $\ket{c}$.
\end{enumerate}
The first step of the algorithm creates a cascade of 1's starting from the
$top(x)$ bit and moving to the right, transforming $c$ into a bitstring of all
1. Then, the second step of the algorithm repeatedly flips the left-most 1 in
the binary representation of $c$ until $c = 1$. Thus, this algorithm converts
$\ket{x}$ to $\ket{1}$. In addition, the first step uses one CX gate for every
zero to the right of $top(x)$, or $holes(x)$ CX gates, while the second
step uses $top(x)$ CX gates, for a total of $top(x) + holes(x)$ CX gates. This
proves the first statement.

To prove the second statement, we show that if $top(x') = top(x)$, then 
$|holes(x) - holes(x')| \leq 1$ and if $top(x') \neq top(x)$, then 
$top(x') \geq top(x) - 1$ and $holes(x) = holes(x')$.
Applying a CX gate to $x$ can change at most one bit in its binary 
representation, so if $top(x)$ is unchanged, then $holes(x)$ can change by at
most 1. Next, consider the possible ways a CX gate can modify $top(x)$: either
a zero bit to the left of $top(x)$ is converted to a one, or the one bit at
$top(x)$ is converted to a zero. In the former case, given the nearest-neighbor
connectivity restriction, the CX gate applied must have used $top(x)$ as its
control qubit, targeting qubit $top(x) + 1$. This transformation causes $top(x)$
to increase by 1, but $holes(x)$ is unchanged. Otherwise, the CX gate applied
must have used $top(x) - 1$ as the control qubit, and $top(x)$ was the target
qubit. This implies the bit at $top(x) - 1$ is a one, therefore, this
transformation decreases $top(x)$ by 1 but keeps $holes(x)$ the same. In all
cases, either $holes(x)$ decreases by at most 1 while $top(x)$ stays the same,
or $top(x)$ decreases by at most 1, leaving $holes(x)$ the same, thus, the
quantity $top(x) + holes(x)$ can decrease by at most one for each CX gate
applied. This concludes the proof that $\text{CXdist}_1(x) = top(x) + holes(x)$.

To compute CXdist($x$), define:
$$bot(x) = max(c) \textit{ s.t. } \frac{x}{2^c} \text{ is an integer}$$
$$holes^*(x) = holes(x) - bot(x)$$
If $x$ is written in its binary representation, then $bot(x)$ is the lowest
index where $x$ has a 1, and $holes^*(x)$ is the number of zero bits between
$top(x)$ and $bot(x)$.

Then we claim:
$$\text{CXdist}(x) = top(x) - bot(x) + holes^*(x)$$

To prove this, we show:
\begin{enumerate}
    \item It is always possible to transform $\ket{x}$ to $\ket{2^{bot(x)}}$
      using $top(x) - bot(x) + holes^*(x)$ CX gates.
    \item If a CX gate transforms $\ket{x}$ to $\ket{x'}$, then
      $$top(x') - bot(x') + holes^*(x') \geq top(x) - bot(x) + holes^*(x) - 1$$
\end{enumerate}

The second statement shows that the quantity $top(x) - bot(x) + holes^*(x)$ can
decrease by at most 1 each time a CX gate is applied. Since this quantity is
zero for all powers of 2, it takes at least $top(x) - bot(x) + holes^*(x)$ CX
gates to transform $\ket{x}$ to a power of 2. The first statement shows this can
always be done, so the statements taken together prove 
$\text{CXdist}($x$) = top(x) - bot(x) + holes^*(x)$.

To prove the first statement, we construct a list $l$ of CX gates that
transforms $\ket{x}$ to $\ket{2^{bot(x)}}$. Let $\ket{c}$ be the state after
applying each gate in $l$ to $\ket{x}$. At the start of the construction,
$\ket{x} = \ket{c}$; at the end, $\ket{c} = \ket{2^{bot(x)}}$.
\begin{enumerate}
  \item For $i$ in $[top(x), top(x) - 1, ..., bot(x) + 1]$, if the $i - 1$th bit
  in $c$ is zero, then add CX($i$, $i - 1$) to $l$ and update $\ket{c}$.
  \item For $i$ in $[top(x), ..., bot(x) + 1]$, add CX($i - 1$, $i$) to $l$ and
  update $\ket{c}$.
\end{enumerate}

The sequence of CX gates in the first step flips all bits in $c$ between 
$top(x)$ and $bot(x)$ to 1, and the sequence of CX gates in the second step
flips all bits in $c$ between $bot(x) + 1$ and $top(x)$ to 0, thus transforming
$\ket{x}$ to $\ket{2^{bot(x)}}$. The first step requires $holes^*(x)$ CX gates
while the second step requires $top(x) - bot(x)$ CX gates, for the promised
total of $top(x) - bot(x) + holes^*(x)$ CX gates, proving the first statement.

To prove the second statement, we argue that if applying a CX gate to $\ket{x}$
generates the state $\ket{x'}$, then
\begin{itemize}
	\item If $top(x') \neq top(x)$, then $|top(x') - top(x)| \leq 1$, 
		$bot(x') = bot(x)$, and $holes^*(x') = holes^*(x)$.
	\item If $bot(x') \neq bot(x)$, then $bot(x') - bot(x)| \leq 1$,
		$top(x') = top(x)$, and $holes^*(x') = holes^*(x)$.
	\item If $top(x') = top(x)$ and $bot(x') = bot(x)$, then
		$|holes^*(x') - holes^*(x)| \leq 1$.
\end{itemize}

To prove the first point, we recycle the observation from before that
$top(x') \neq top(x)$ implies $|top(x') - top(x)| = 1$ and 
$|holes(x') - holes(x)| = 0$. Thus, all that's left is to show 
$bot(x') = bot(x)$. This can be seen by noting if $top(x') > top(x)$, then the 
flipped bit was to the left of $top(x)$, which is to the left of $bot(x)$;
otherwise the flipped bit was $top(x)$ and the bit at $top(x) - 1$ is a one,
which implies $bot(x) \leq top(x) - 1$, thus $bot(x)$ is to the right of the
flipped bit. In both cases, the changed bit is to the left of $bot(x)$, thus,
$bot(x) = bot(x')$.

To prove the second point, note that it's a restatement of the first point but
with the bits in reverse order. Thus, the symmetric argument of the first point
shows the second point.

Finally, if $top(x)$ and $bot(x)$ are the same, we recycle the observation from
before that a CX gate flips at most one bit, therefore $holes(x')$ differs from
$holes(x)$ by at most one, which implies $holes^*(x')$ differs from
$holes^*(x)$ by at most one (because $bot(x') = bot(x)$.

In all cases, at most one of $\{top(x) - top(x'), bot(x) - bot(x'), 
holes^*(x) - holes^*(x')\}$ will be nonzero, and that value will have absolute
value less than one, showing that $top(x) - bot(x) + holes^*(x)$ will decrease
by at most one for each CX gate applied. This completes the proof that
$\text{CXdist}(x) = top(x) - bot(x) + holes^*(x)$.

\subsection{CX gate count for UCG exact method on linear nearest neighbor 
architecture}
Bergholm et al \cite{bergholm2005quantum} showed that exact quantum 
state preparation on $n$ qubits
can be reduced to a sequence of $n$ uniformly controlled single-qubit gates,
where the $k$th gate uses qubits $[0 ... n - 1 - k]$ as the controls, and qubit
$n - k$ as the target. The last UCG is a single-qubit rotation on qubit 0. 
Next, the authors showed that, on linear nearest neighbor architectures,
a uniformly controlled single-qubit gate using controls $[0 ... c - 1]$ and 
target qubit $c$ can be implemented, up to a diagonal phase gate, as:
$$UCG(c) = \prod_{i=0}^{2^c - 1}{\text{CX chain}(c - 1 - z(i), c)U(i)}$$
For some choice of single-qubit rotations $U(i)$, where $z(i)$ is the number
of trailing zeroes in the binary representation of $i$ (define $z(0) = c - 1$,
$\frac{i}{2^{z(i)}}$ is an odd integer for $i > 0$)
and CX chain($i$, $j$) is a sequence of CX gates:
\begin{multline} \label{CX_chain}
\text{CX chain}(i, j) = CX(i, i + 1) CX(i + 1, i + 2) ... CX(j - 2, j - 1)
  CX(j - 1, j)\\
  CX(j - 2, j - 1) ... CX(i + 1, i + 2)CX(i, i + 1)
\end{multline}

The number of CX gates in CX chain($i$, $j$) is $2(j - i) - 1$. Then, the
number of CX gates needed to implement a $UCG(c)$ is
$$\text{CX count(UCG(\textit{c}))} = \sum_{i=0}^{2^c - 1}{(2(1 + z(i)) - 1)}$$
$$ = \sum_{i=0}^{2^c - 1}{(2z(i) + 1)}$$
$$ = 2^c + 2\sum_{i=0}^{2^c - 1}{z(i)}$$

Since $i$ takes on all nonnegative integers with $c$ bits in the sum, there 
are $2^{c-m-1}$ instances where $z(i) = m$, for $0 \leq m \leq c - 2$.
By contrast, $m = c - 1$ will show up twice because $z(0)$ is defined to be 
$c - 1$. Then,
$$\sum_{i=0}^{2^c - 1}{z(i)} = \sum_{m=0}^{c - 2}{m2^{c-m-1}} + 2(c - 1) = 2^c - 2$$
$$\text{CX count(UCG(\textit{c}))} = 2^c + 2(2^c - 2) = 3 \times 2^c - 4$$

This would be the number of CX gates required to implement UCG($c$) on a linear
nearest neighbor architecture, however, \cite{bergholm2005quantum} introduces
an optimization: by swapping qubits $c$ and $c - 1$ all of the 
$\text{CX chain}(c - 1 - z(i), c)$ terms in eqn. (\ref{CX_chain}), where
$c - 1 - z(i) < c - 1$ will become $\text{CX chain}(c - 1 - z(i), c - 1)$. This
leads to a cost reduction of 2 CX gates for each of these terms. In addition,
for the CX chains where $c - 1 - z(i) = c - 1$, 
$\text{CX chain}(c - 1 - z(i), c) = \text{CX chain}(c - 1, c)$ becomes
$\text{CX chain}(c, c - 1)$, which is the same thing. The swapping procedure
costs 6 CX gates (3 to swap the qubits, 3 to swap them back at the end), but it
saves 2 CX gates for each term where $c - 1 - z(i) < c - 1 \implies z(i) > 0$.
There are $2^{c - 1}$ such terms, leading to a net savings of $2^c - 6$ CX
gates. Thus, we modify the CX count for UCG($c$) gates:
$$\text{CX count, optimized}(\text{UCG}(c)) 
= 3\times2^c - 4 - (2^c - 6) = 2 \times 2^c + 2$$

We introduce one additional optimization: the UCG(2), UCG(1), and UCG(0) gates
at the end can be replaced by the exact, optimal three-qubit state preparation
procedure. Then, we can compute the total number of CX gates required to prepare
an $n$-qubit quantum state ($n > 3$) using the UCG method:

$$\text{CX count, UCG on \textit{n} qubits} = \sum_{k=3}^{n - 1}{2 \times 2^k + 2} + 3$$
$$ = 2(2^n - 8) + 2(n - 3) + 3 = 2 \times 2^n + 2n - 19$$.

\bibliographystyle{unsrt}
\bibliography{references}
\end{document}
